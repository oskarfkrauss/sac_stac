{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Utils\n",
    "\n",
    "> Basic utility functions across sac_stac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "from glob import glob\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "import boto3\n",
    "import gdal\n",
    "from pystac import STAC_IO\n",
    "\n",
    "from sedas_pyapi.sedas_api import SeDASAPI\n",
    "from sedas_pyapi.bulk_download import SeDASBulkDownload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably best if we start by logging into sedas to be able to access datasets in their current format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_client():\n",
    "    \"Log into sedas api.\"\n",
    "    sedas = SeDASAPI(os.getenv('SEDAS_USERNAME'), os.getenv('SEDAS_PWD'))\n",
    "    sedas.base_url=\"https://geobrowsertest.satapps.org/api/\"\n",
    "    return sedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sedas_pyapi.sedas_api.SeDASAPI at 0x7f870f13b450>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sedas_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should inc. test for env vars...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll want to find datasets from different *Collections*, which sedas expects as *groups*. Will eventually **need to add test endpoint** to be able to access NovaSAR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_get_collections():\n",
    "    sedas = sedas_client()\n",
    "    result_groups = sedas.list_sensor_groups()\n",
    "    groups = []\n",
    "    for i in range(0, len(result_groups)):\n",
    "        groups.append(result_groups[i]['name'])\n",
    "    return f\"Available groups are: {', '.join(groups)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Available groups are: Cosmo-SkyMed, SPOT, Pleiades, S1, S2, AIRSAR'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sedas_get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_find_datasets(wkt, startDate, endDate, collection):\n",
    "    optical_groups = ['S2','Pleiades','SPOT']\n",
    "    sar_groups = ['S1','Cosmo-SkyMed','AIRSAR']\n",
    "    sedas = sedas_client()\n",
    "    if collection in optical_groups: \n",
    "        res = sedas.search_optical(wkt, startDate, endDate, source_group=collection) \n",
    "    elif collection in sar_groups:\n",
    "        res = sedas.search_sar(wkt, startDate, endDate, source_group=collection)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for a small area over Oxford we can find..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>supplierId</th>\n",
       "      <th>type</th>\n",
       "      <th>satelliteName</th>\n",
       "      <th>instrumentName</th>\n",
       "      <th>modeName</th>\n",
       "      <th>sensorType</th>\n",
       "      <th>sensorResolution</th>\n",
       "      <th>coordinatesWKT</th>\n",
       "      <th>start</th>\n",
       "      <th>...</th>\n",
       "      <th>area</th>\n",
       "      <th>aoiCoveragePercent</th>\n",
       "      <th>usefulAreaPercent</th>\n",
       "      <th>cloudCoveragePercent</th>\n",
       "      <th>productType</th>\n",
       "      <th>latency</th>\n",
       "      <th>ql</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>vendorSpecific</th>\n",
       "      <th>downloadUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0ec9a5f12356e87bc910ddbc49dbb76</td>\n",
       "      <td>Pleiades_UKSA396_SO18034616-96-01_DS_PHR1B_201...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1B</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.654728 51.309517,-1.345414 51.3081...</td>\n",
       "      <td>2018-10-24T11:17:22Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.825125e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': 'cf...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94cc7887414be0912de7ca44288f79da</td>\n",
       "      <td>Pleiades_UKSA174_SO18034614-74-01_DS_PHR1A_201...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1A</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-2.153852 51.603313,-1.841533 51.6033...</td>\n",
       "      <td>2018-09-29T11:10:08Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.565260e+08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': '4b...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6ac7da92a92161839c0bf29ab1b878d3</td>\n",
       "      <td>Pleiades_UKSA173_SO18034614-73-01_DS_PHR1A_201...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1A</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.903588 51.628784,-1.592515 51.6281...</td>\n",
       "      <td>2018-09-29T11:10:00Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796598e+08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': 'e6...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd08a178209ed51cc57f5caef1e1ad7c</td>\n",
       "      <td>Pleiades_UKSA341_SO18034616-41-01_DS_PHR1B_201...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1B</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.401923 51.155725,-1.101068 51.1538...</td>\n",
       "      <td>2018-09-02T11:17:34Z</td>\n",
       "      <td>...</td>\n",
       "      <td>8.211908e+08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': 'a5...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97528406bc14d1c94ef22d20b4b26c7a</td>\n",
       "      <td>Pleiades_UKSA305_SO18034616-5-01_DS_PHR1B_2018...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1B</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.576165 51.728406,-1.265721 51.7268...</td>\n",
       "      <td>2018-07-24T11:24:30Z</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256422e+08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': '77...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3e8d4c9096b3ba5c7126499e442424f5</td>\n",
       "      <td>Pleiades_UKSA87_SO18034613-87-01_DS_PHR1A_2018...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1A</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.413484 51.469752,-1.089638 51.4676...</td>\n",
       "      <td>2018-06-29T11:18:17Z</td>\n",
       "      <td>...</td>\n",
       "      <td>9.264473e+08</td>\n",
       "      <td>34.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': '7f...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b5ff24c70eba28f3ec7292c356fb27b0</td>\n",
       "      <td>Pleiades_UKSA204_SO18034615-4-01_DS_PHR1B_2018...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1B</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.928964 51.516819,-1.63821 51.51628...</td>\n",
       "      <td>2018-02-25T11:21:25Z</td>\n",
       "      <td>...</td>\n",
       "      <td>2.385591e+08</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': '4b...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92fe8121944a5267861d31597afb016a</td>\n",
       "      <td>Pleiades_UKSA7_SO18034613-7-01_DS_PHR1A_201802...</td>\n",
       "      <td>ARCHIVE</td>\n",
       "      <td>Pleiades-1A</td>\n",
       "      <td>MS/PAN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Optical</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON((-1.606218 51.306711,-1.294645 51.3052...</td>\n",
       "      <td>2018-02-24T11:27:55Z</td>\n",
       "      <td>...</td>\n",
       "      <td>6.639221e+08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>https://geobrowser.satapps.org/archiveql/aeweb...</td>\n",
       "      <td>https://sedasdm.satapps.org/qls/qlmgr.php?scen...</td>\n",
       "      <td>{'property': 'vendorSpecific', 'Filehash': 'ef...</td>\n",
       "      <td>https://sedasdm.satapps.org/datamgr/datamgr.ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          productId  \\\n",
       "0  c0ec9a5f12356e87bc910ddbc49dbb76   \n",
       "1  94cc7887414be0912de7ca44288f79da   \n",
       "2  6ac7da92a92161839c0bf29ab1b878d3   \n",
       "3  dd08a178209ed51cc57f5caef1e1ad7c   \n",
       "4  97528406bc14d1c94ef22d20b4b26c7a   \n",
       "5  3e8d4c9096b3ba5c7126499e442424f5   \n",
       "6  b5ff24c70eba28f3ec7292c356fb27b0   \n",
       "7  92fe8121944a5267861d31597afb016a   \n",
       "\n",
       "                                          supplierId     type satelliteName  \\\n",
       "0  Pleiades_UKSA396_SO18034616-96-01_DS_PHR1B_201...  ARCHIVE   Pleiades-1B   \n",
       "1  Pleiades_UKSA174_SO18034614-74-01_DS_PHR1A_201...  ARCHIVE   Pleiades-1A   \n",
       "2  Pleiades_UKSA173_SO18034614-73-01_DS_PHR1A_201...  ARCHIVE   Pleiades-1A   \n",
       "3  Pleiades_UKSA341_SO18034616-41-01_DS_PHR1B_201...  ARCHIVE   Pleiades-1B   \n",
       "4  Pleiades_UKSA305_SO18034616-5-01_DS_PHR1B_2018...  ARCHIVE   Pleiades-1B   \n",
       "5  Pleiades_UKSA87_SO18034613-87-01_DS_PHR1A_2018...  ARCHIVE   Pleiades-1A   \n",
       "6  Pleiades_UKSA204_SO18034615-4-01_DS_PHR1B_2018...  ARCHIVE   Pleiades-1B   \n",
       "7  Pleiades_UKSA7_SO18034613-7-01_DS_PHR1A_201802...  ARCHIVE   Pleiades-1A   \n",
       "\n",
       "  instrumentName modeName sensorType  sensorResolution  \\\n",
       "0         MS/PAN    0.000    Optical               2.0   \n",
       "1         MS/PAN    0.000    Optical               2.0   \n",
       "2         MS/PAN    0.000    Optical               2.0   \n",
       "3         MS/PAN    0.000    Optical               2.0   \n",
       "4         MS/PAN    0.000    Optical               2.0   \n",
       "5         MS/PAN    0.000    Optical               2.0   \n",
       "6         MS/PAN    0.000    Optical               2.0   \n",
       "7         MS/PAN    0.000    Optical               2.0   \n",
       "\n",
       "                                      coordinatesWKT                 start  \\\n",
       "0  POLYGON((-1.654728 51.309517,-1.345414 51.3081...  2018-10-24T11:17:22Z   \n",
       "1  POLYGON((-2.153852 51.603313,-1.841533 51.6033...  2018-09-29T11:10:08Z   \n",
       "2  POLYGON((-1.903588 51.628784,-1.592515 51.6281...  2018-09-29T11:10:00Z   \n",
       "3  POLYGON((-1.401923 51.155725,-1.101068 51.1538...  2018-09-02T11:17:34Z   \n",
       "4  POLYGON((-1.576165 51.728406,-1.265721 51.7268...  2018-07-24T11:24:30Z   \n",
       "5  POLYGON((-1.413484 51.469752,-1.089638 51.4676...  2018-06-29T11:18:17Z   \n",
       "6  POLYGON((-1.928964 51.516819,-1.63821 51.51628...  2018-02-25T11:21:25Z   \n",
       "7  POLYGON((-1.606218 51.306711,-1.294645 51.3052...  2018-02-24T11:27:55Z   \n",
       "\n",
       "   ...          area aoiCoveragePercent  usefulAreaPercent  \\\n",
       "0  ...  4.825125e+08                1.0                5.0   \n",
       "1  ...  1.565260e+08                2.0               22.0   \n",
       "2  ...  1.796598e+08               10.0              100.0   \n",
       "3  ...  8.211908e+08                1.0                1.0   \n",
       "4  ...  4.256422e+08               11.0               46.0   \n",
       "5  ...  9.264473e+08               34.0               67.0   \n",
       "6  ...  2.385591e+08               12.0               94.0   \n",
       "7  ...  6.639221e+08               11.0               29.0   \n",
       "\n",
       "   cloudCoveragePercent  productType   latency  \\\n",
       "0                   0.0           L3  Standard   \n",
       "1                   0.0           L3  Standard   \n",
       "2                   0.0           L3  Standard   \n",
       "3                   0.0           L3  Standard   \n",
       "4                   1.0           L3  Standard   \n",
       "5                   0.0           L3  Standard   \n",
       "6                   0.0           L3  Standard   \n",
       "7                   0.0           L3  Standard   \n",
       "\n",
       "                                                  ql  \\\n",
       "0  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "1  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "2  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "3  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "4  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "5  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "6  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "7  https://geobrowser.satapps.org/archiveql/aeweb...   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "1  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "2  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "3  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "4  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "5  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "6  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "7  https://sedasdm.satapps.org/qls/qlmgr.php?scen...   \n",
       "\n",
       "                                      vendorSpecific  \\\n",
       "0  {'property': 'vendorSpecific', 'Filehash': 'cf...   \n",
       "1  {'property': 'vendorSpecific', 'Filehash': '4b...   \n",
       "2  {'property': 'vendorSpecific', 'Filehash': 'e6...   \n",
       "3  {'property': 'vendorSpecific', 'Filehash': 'a5...   \n",
       "4  {'property': 'vendorSpecific', 'Filehash': '77...   \n",
       "5  {'property': 'vendorSpecific', 'Filehash': '7f...   \n",
       "6  {'property': 'vendorSpecific', 'Filehash': '4b...   \n",
       "7  {'property': 'vendorSpecific', 'Filehash': 'ef...   \n",
       "\n",
       "                                         downloadUrl  \n",
       "0  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "1  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "2  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "3  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "4  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "5  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "6  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "7  https://sedasdm.satapps.org/datamgr/datamgr.ph...  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sedas_find_datasets(\"POLYGON((-1.91 51.81,-1.15 51.81,-1.15 51.50,-1.91 51.50,-1.91 51.81))\", \n",
    "                             \"2000-01-01T00:00:00Z\", \n",
    "                             \"2020-10-27T00:00:00Z\",\n",
    "                             \"Pleiades\"\n",
    "                            )\n",
    "pd.DataFrame(result['products'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a single download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def sedas_download(sedas_res_dict, down_zip, sedas=None):\n",
    "#     \"Use product dict to download product zip.\"\n",
    "#     if not sedas:\n",
    "#         sedas = sedas_client()\n",
    "#     sedas.download(sedas_res_dict, down_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_download(sedas_res_dicts, down_dir, sedas=None):\n",
    "    \"Use product dicts list to download into a dir.\"\n",
    "    if not sedas:\n",
    "        sedas = sedas_client()\n",
    "    downloader = SeDASBulkDownload(sedas, down_dir, parallel=2)\n",
    "    downloader.add(sedas_res_dicts)\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Downloading\")\n",
    "    while not downloader.is_done():\n",
    "        time.sleep(5)\n",
    "    downloader.shutdown()\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_extract(down_zip, scene_dir):\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Extracting {down_zip}\")\n",
    "    with zipfile.ZipFile(down_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(scene_dir)\n",
    "    if os.path.exists(scene_dir):\n",
    "        os.remove(down_zip)\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Extracted to {scene_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud-Optimised Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have access to the datasets, we will want to convert raster images of any format into a default COG format. (It helps that COGs are now an official [gdal driver](https://gdal.org/drivers/raster/cog.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert2cog(img_path, cog_path, band):\n",
    "    \"\"\"\n",
    "    Convert gdal raster into COG with default settings.\n",
    "    Considering lzw compression.\n",
    "    See https://www.cogeo.org/developers-guide.html.\n",
    "    \"\"\"\n",
    "    # translate into new cog file\n",
    "    kwargs = {\n",
    "        'format': 'COG',\n",
    "#         'creationOptions' : ['COMPRESS=LZW'],\n",
    "        'bandList': [band]\n",
    "    }\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Starting conversion: {img_path}.\")\n",
    "    ds = gdal.Translate(cog_path, img_path, **kwargs)\n",
    "    ds = None\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Conversion complete: {os.path.exists(cog_path)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mosaic2cog(imgs, out_cog, band):\n",
    "    \"\"\"\n",
    "    Mosaic imgs into cog.\n",
    "    Usual vrt assumptions.\n",
    "    \"\"\"\n",
    "    tmp_vrt = f\"{out_cog[:-4]}_mosaic.tif\"\n",
    "    # mosaic into vrt\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Mosaicing band {band} imgs: {imgs}\")\n",
    "    ds = gdal.BuildVRT(tmp_vrt, imgs, bandList=[band])\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Mosaicd {tmp_vrt}\")\n",
    "    # write vrt mosaic to cog\n",
    "    convert2cog(ds, out_cog, 1)\n",
    "    ds = None\n",
    "\n",
    "    if os.path.exists(tmp_vrt):\n",
    "        os.remove(tmp_vrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mosaic currently specific to pleiades ([:-13] for slicing name). Needs to be generalised a little more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cogmosaicbands(img_paths, numbands, basename):\n",
    "    \"\"\"\n",
    "    Convert bands from img_paths to cog, output \n",
    "    basename_band#.tif. Mosaic if >1 img paths.\n",
    "    \"\"\"\n",
    "    if len(img_paths) == 1:\n",
    "        for b in range(1, numbands+1):\n",
    "            convert2cog(img_paths[0], f\"{basename}_band{b}.tif\", b)\n",
    "        for f in glob(f\"{img_paths[0][:-4]}*\"):\n",
    "            os.remove(f)\n",
    "    elif len(img_paths) > 1:\n",
    "        for b in range(1, numbands+1):\n",
    "            mosaic2cog(img_paths[0], f\"{basename}_band{b}.tif\", b)\n",
    "        for img_path in img_paths:\n",
    "            for f in glob(f\"{img_path[:-4]}*\"):\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_create_client(s3_bucket):\n",
    "    \"\"\"\n",
    "    Create and set up a connection to S3\n",
    "    :param s3_bucket:\n",
    "    :return: the s3 client object.\n",
    "    \"\"\"\n",
    "    access = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    secret = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "    session = boto3.Session(\n",
    "        access,\n",
    "        secret,\n",
    "    )\n",
    "    endpoint_url = os.getenv(\"AWS_S3_ENDPOINT_URL\")\n",
    "\n",
    "    if endpoint_url is not None:\n",
    "        s3 = session.resource('s3', endpoint_url=endpoint_url)\n",
    "    else:\n",
    "        s3 = session.resource('s3', region_name='eu-west-2')\n",
    "\n",
    "    bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "    if endpoint_url is not None:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=access,\n",
    "            aws_secret_access_key=secret,\n",
    "            endpoint_url=endpoint_url\n",
    "        )\n",
    "    else:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=access,\n",
    "            aws_secret_access_key=secret\n",
    "        )\n",
    "    return s3_client, bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to connect to any S3-like object storage end point. Assumes env vars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "gb = 1024 ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_single_upload(in_path, s3_path, s3_bucket):\n",
    "    \"\"\"\n",
    "    put a file into S3 from the local file system.\n",
    "    :param in_path: a path to a file on the local file system\n",
    "    :param s3_path: where in S3 to put the file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # prep session & creds\n",
    "    s3_client, bucket = s3_create_client(s3_bucket)\n",
    "\n",
    "    # Ensure that multipart uploads only happen if the size of a transfer is larger than\n",
    "    # S3's size limit for non multipart uploads, which is 5 GB. we copy using multipart \n",
    "    # at anything over 4gb\n",
    "    transfer_config = boto3.s3.transfer.TransferConfig(multipart_threshold=2 * gb,\n",
    "                                                       max_concurrency=10,\n",
    "                                                       multipart_chunksize=2 * gb,\n",
    "                                                       use_threads=True)\n",
    "    s3_client.upload_file(in_path, bucket.name, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_rel_dir_s3_paths(local_dir, s3_dir):\n",
    "    \"\"\"\n",
    "    returns local path, remote path pair list.\n",
    "    \"\"\"  \n",
    "    paths = []\n",
    "    for subdir, dirs, files in os.walk(local_dir):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(subdir, file)\n",
    "            paths.append([ full_path, s3_dir + local_dir.split('/')[-2] + full_path[len(local_dir):] ])\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_upload_dir(in_dir, s3_bucket, s3_dir):\n",
    "    \"\"\"\n",
    "    Upload all items in directory, inc. dir.\n",
    "    \"\"\"\n",
    "    paths = get_rel_dir_s3_paths(in_dir, s3_dir)\n",
    "    upload_list = [(in_path, out_path, s3_bucket)\n",
    "                   for in_path, out_path in paths]\n",
    "    for i in upload_list:\n",
    "        s3_single_upload(i[0], i[1], i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_list_objects_paths(s3_bucket, prefix):\n",
    "    \"\"\"List of paths only returned, not full object responses\"\"\"\n",
    "    client, bucket = s3_create_client(s3_bucket)\n",
    "    \n",
    "    return [e['Key'] for p in client.get_paginator(\"list_objects_v2\").paginate(Bucket=s3_bucket, Prefix=prefix) for e in p['Contents']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_list_objects(s3_bucket, prefix):\n",
    "    # prep session & creds\n",
    "    client, bucket = s3_create_client(s3_bucket)\n",
    "    response = client.list_objects_v2(Bucket=s3_bucket, Prefix=prefix)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_up(work_dir):\n",
    "    # TODO: sort out logging changes...\n",
    "    gc.collect()\n",
    "    shutil.rmtree(work_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can amend the default STAC I/O tools to work with our object storage.\n",
    "\n",
    "First up is to be able to create a uri given an endpoint, bucket name and object path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_uri(s3_path, s3_bucket='public-eo-data', endpoint_url=os.getenv('AWS_S3_ENDPOINT_URL')):    \n",
    "    return f\"{endpoint_url}/{s3_bucket}/{s3_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amend the reading method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def my_read_method(uri):\n",
    "    parsed = urlparse(uri)\n",
    "    if parsed.scheme == 's3':\n",
    "        bucket = parsed.netloc\n",
    "        key = parsed.path[1:]\n",
    "        s3 = boto3.resource('s3')\n",
    "        obj = s3.Object(bucket, key)\n",
    "        return obj.get()['Body'].read().decode('utf-8')\n",
    "    else:\n",
    "        return STAC_IO.default_read_text_method(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the writing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def my_write_method(uri, txt):\n",
    "    parsed = urlparse(uri)\n",
    "    if parsed.scheme == 's3':\n",
    "        bucket = parsed.netloc\n",
    "        key = parsed.path[1:]\n",
    "        s3 = boto3.resource(\"s3\")\n",
    "        s3.Object(bucket, key).put(Body=txt)\n",
    "    else:\n",
    "        STAC_IO.default_write_text_method(uri, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then allow us to overwrite the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pystac_setIO():\n",
    "    STAC_IO.read_text_method = my_read_method\n",
    "    STAC_IO.write_text_method = my_write_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_pleiades.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
