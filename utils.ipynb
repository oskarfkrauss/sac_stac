{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Utils\n",
    "\n",
    "> Basic utility functions across sac_stac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "from glob import glob\n",
    "from urllib.parse import urlparse\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import gdal\n",
    "from pystac import StacIO\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from sedas_pyapi.sedas_api import SeDASAPI\n",
    "from sedas_pyapi.bulk_download import SeDASBulkDownload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sedas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably best if we start by logging into sedas to be able to access datasets in their current format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_client():\n",
    "    \"Log into sedas api.\"\n",
    "    sedas = SeDASAPI(os.getenv('SEDAS_USERNAME'), os.getenv('SEDAS_PWD'))\n",
    "    sedas.base_url=\"https://geobrowsertest.satapps.org/api/\"\n",
    "    return sedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 405: Not Allowed\n",
      "<html>\n",
      "<head><title>405 Not Allowed</title></head>\n",
      "<body>\n",
      "<center><h1>405 Not Allowed</h1></center>\n",
      "<hr><center>nginx/1.16.0</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 405: Not Allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6528c3f1ce2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msedas_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-cdb76fd88519>\u001b[0m in \u001b[0;36msedas_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msedas_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Log into sedas api.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msedas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeDASAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SEDAS_USERNAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SEDAS_PWD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msedas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://geobrowsertest.satapps.org/api/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msedas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sedas_pyapi/sedas_api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, username, password)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_username\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__password\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sedas_pyapi/sedas_api.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     def search(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sedas_pyapi/sedas_api.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         )\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Token {self._token}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 405: Not Allowed"
     ]
    }
   ],
   "source": [
    "sedas_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should inc. test for env vars...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll want to find datasets from different *Collections*, which sedas expects as *groups*. Will eventually **need to add test endpoint** to be able to access NovaSAR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_get_collections():\n",
    "    sedas = sedas_client()\n",
    "    result_groups = sedas.list_sensor_groups()\n",
    "    groups = []\n",
    "    for i in range(0, len(result_groups)):\n",
    "        groups.append(result_groups[i]['name'])\n",
    "    return f\"Available groups are: {', '.join(groups)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sedas_get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_find_datasets(wkt, startDate, endDate, collection):\n",
    "    optical_groups = ['S2','Pleiades','SPOT']\n",
    "    sar_groups = ['S1','Cosmo-SkyMed','AIRSAR']\n",
    "    sedas = sedas_client()\n",
    "    if collection in optical_groups: \n",
    "        res = sedas.search_optical(wkt, startDate, endDate, source_group=collection) \n",
    "    elif collection in sar_groups:\n",
    "        res = sedas.search_sar(wkt, startDate, endDate, source_group=collection)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for a small area over Oxford we can find..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sedas_find_datasets(\"POLYGON((-1.91 51.81,-1.15 51.81,-1.15 51.50,-1.91 51.50,-1.91 51.81))\", \n",
    "                             \"2000-01-01T00:00:00Z\", \n",
    "                             \"2020-10-27T00:00:00Z\",\n",
    "                             \"Pleiades\"\n",
    "                            )\n",
    "pd.DataFrame(result['products']).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a single download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_download(sedas_res_dicts, down_dir, sedas=None):\n",
    "    \"Use product dicts list to download into a dir.\"\n",
    "    if not sedas:\n",
    "        sedas = sedas_client()\n",
    "    downloader = SeDASBulkDownload(sedas, down_dir, parallel=2)\n",
    "    downloader.add(sedas_res_dicts)\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Downloading\")\n",
    "    while not downloader.is_done():\n",
    "        time.sleep(5)\n",
    "    downloader.shutdown()\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sedas_extract(down_zip, scene_dir):\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Extracting {down_zip}\")\n",
    "    with zipfile.ZipFile(down_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(scene_dir)\n",
    "    if os.path.exists(scene_dir):\n",
    "        os.remove(down_zip)\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Extracted to {scene_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud-Optimised Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have access to the datasets, we will want to convert raster images of any format into a default COG format. (It helps that COGs are now an official [gdal driver](https://gdal.org/drivers/raster/cog.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert2cog(img_path, cog_path, band):\n",
    "    \"\"\"\n",
    "    Convert gdal raster into COG with default settings.\n",
    "    Considering lzw compression.\n",
    "    See https://www.cogeo.org/developers-guide.html.\n",
    "    \"\"\"\n",
    "    # translate into new cog file\n",
    "    kwargs = {\n",
    "        'format': 'COG',\n",
    "#         'creationOptions' : ['COMPRESS=LZW'],\n",
    "        'bandList': [band]\n",
    "    }\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Starting conversion: {img_path}.\")\n",
    "    ds = gdal.Translate(cog_path, img_path, **kwargs)\n",
    "    ds = None\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Conversion complete: {os.path.exists(cog_path)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mosaic2cog(imgs, out_cog, band):\n",
    "    \"\"\"\n",
    "    Mosaic imgs into cog.\n",
    "    Usual vrt assumptions.\n",
    "    \"\"\"\n",
    "    tmp_vrt = f\"{out_cog[:-4]}_mosaic.tif\"\n",
    "    # mosaic into vrt\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Mosaicing band {band} imgs: {imgs}\")\n",
    "    ds = gdal.BuildVRT(tmp_vrt, imgs, bandList=[band])\n",
    "    print(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} Mosaicd {tmp_vrt}\")\n",
    "    # write vrt mosaic to cog\n",
    "    convert2cog(ds, out_cog, 1)\n",
    "    ds = None\n",
    "\n",
    "    if os.path.exists(tmp_vrt):\n",
    "        os.remove(tmp_vrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mosaic currently specific to pleiades ([:-13] for slicing name). Needs to be generalised a little more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cogmosaicbands(img_paths, numbands, basename):\n",
    "    \"\"\"\n",
    "    Convert bands from img_paths to cog, output \n",
    "    basename_band#.tif. Mosaic if >1 img paths.\n",
    "    \"\"\"\n",
    "    if len(img_paths) == 1:\n",
    "        for b in range(1, numbands+1):\n",
    "            convert2cog(img_paths[0], f\"{basename}_band{b}.tif\", b)\n",
    "        for f in glob(f\"{img_paths[0][:-4]}*\"):\n",
    "            os.remove(f)\n",
    "    elif len(img_paths) > 1:\n",
    "        for b in range(1, numbands+1):\n",
    "            mosaic2cog(img_paths[0], f\"{basename}_band{b}.tif\", b)\n",
    "        for img_path in img_paths:\n",
    "            for f in glob(f\"{img_path[:-4]}*\"):\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def s3_create_client(s3_bucket):\n",
    "    \"\"\"\n",
    "    Create and set up a connection to S3\n",
    "    :param s3_bucket:\n",
    "    :return: the s3 client object.\n",
    "    \"\"\"\n",
    "    access = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "    secret = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "    session = boto3.Session(\n",
    "        access,\n",
    "        secret,\n",
    "    )\n",
    "    endpoint_url = os.getenv(\"AWS_S3_ENDPOINT_URL\")\n",
    "\n",
    "    if endpoint_url is not None:\n",
    "        s3 = session.resource('s3', endpoint_url=endpoint_url)\n",
    "    else:\n",
    "        s3 = session.resource('s3', region_name='eu-west-2')\n",
    "\n",
    "    bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "    if endpoint_url is not None:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=access,\n",
    "            aws_secret_access_key=secret,\n",
    "            endpoint_url=endpoint_url\n",
    "        )\n",
    "    else:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=access,\n",
    "            aws_secret_access_key=secret\n",
    "        )\n",
    "    return s3_client, bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to connect to any S3-like object storage end point. Assumes env vars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "gb = 1024 ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_single_upload(in_path, s3_path, s3_bucket):\n",
    "    \"\"\"\n",
    "    put a file into S3 from the local file system.\n",
    "    :param in_path: a path to a file on the local file system\n",
    "    :param s3_path: where in S3 to put the file.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # prep session & creds\n",
    "    s3_client, bucket = s3_create_client(s3_bucket)\n",
    "\n",
    "    # Ensure that multipart uploads only happen if the size of a transfer is larger than\n",
    "    # S3's size limit for non multipart uploads, which is 5 GB. we copy using multipart \n",
    "    # at anything over 4gb\n",
    "    transfer_config = boto3.s3.transfer.TransferConfig(multipart_threshold=2 * gb,\n",
    "                                                       max_concurrency=10,\n",
    "                                                       multipart_chunksize=2 * gb,\n",
    "                                                       use_threads=True)\n",
    "    s3_client.upload_file(in_path, bucket.name, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_rel_dir_s3_paths(local_dir, s3_dir):\n",
    "    \"\"\"\n",
    "    returns local path, remote path pair list.\n",
    "    \"\"\"  \n",
    "    paths = []\n",
    "    for subdir, dirs, files in os.walk(local_dir):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(subdir, file)\n",
    "            paths.append([ full_path, s3_dir + local_dir.split('/')[-2] + '/' + full_path[len(local_dir):] ])\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_upload_dir(in_dir, s3_bucket, s3_dir):\n",
    "    \"\"\"\n",
    "    Upload all items in directory, inc. dir.\n",
    "    \"\"\"\n",
    "    paths = get_rel_dir_s3_paths(in_dir, s3_dir)\n",
    "    upload_list = [(in_path, out_path, s3_bucket)\n",
    "                   for in_path, out_path in paths]\n",
    "    for i in upload_list:\n",
    "        s3_single_upload(i[0], i[1], i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def s3_list_objects_paths(s3_bucket, prefix):\n",
    "    \"\"\"List of paths only returned, not full object responses\"\"\"\n",
    "    client, bucket = s3_create_client(s3_bucket)\n",
    "    \n",
    "    return [e['Key'] for p in client.get_paginator(\"list_objects_v2\").paginate(Bucket=s3_bucket, Prefix=prefix) for e in p['Contents']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def s3_list_objects(s3_bucket, prefix):\n",
    "    # prep session & creds\n",
    "    client, bucket = s3_create_client(s3_bucket)\n",
    "    response = client.list_objects_v2(Bucket=s3_bucket, Prefix=prefix)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_up(work_dir):\n",
    "    # TODO: sort out logging changes...\n",
    "    gc.collect()\n",
    "    shutil.rmtree(work_dir)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup_logging():\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    root = logging.getLogger()\n",
    "    root.setLevel(os.environ.get(\"LOGLEVEL\", \"DEBUG\"))\n",
    "\n",
    "    # Turn down rasterio. It is extremely chatty at debug level.\n",
    "    logging.getLogger(\"rasterio\").setLevel(\"INFO\")\n",
    "    logging.getLogger(\"rasterio._io\").setLevel(\"WARNING\")\n",
    "\n",
    "    # Boto Core is also very chatty at debug. Logging entire request text etc\n",
    "    logging.getLogger(\"botocore\").setLevel(\"INFO\")\n",
    "    logging.getLogger(\"boto\").setLevel(\"INFO\")\n",
    "    logging.getLogger(\"boto3.resources\").setLevel(\"INFO\")\n",
    "    logging.getLogger(\"s3transfer\").setLevel(\"INFO\")\n",
    "    logging.getLogger(\"urllib3\").setLevel(\"INFO\")\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_img_crs_and_bbox(raster_uri):\n",
    "    \"\"\"\n",
    "    BBOX list, geometry shapely and rasterio crs from\n",
    "    URI of COG.\n",
    "    nb: footprint currently same as bbo.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_uri) as ds:\n",
    "        bounds = ds.bounds\n",
    "        bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "        footprint = Polygon([\n",
    "            [bounds.left, bounds.bottom],\n",
    "            [bounds.left, bounds.top],\n",
    "            [bounds.right, bounds.top],\n",
    "            [bounds.right, bounds.bottom]\n",
    "        ])\n",
    "        return bbox, footprint, ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can amend the default STAC I/O tools to work with our object storage.\n",
    "\n",
    "First up is to be able to create a uri given an endpoint, bucket name and object path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_uri(s3_path, s3_bucket='public-eo-data', endpoint_url=os.getenv('AWS_S3_ENDPOINT_URL')):    \n",
    "    return f\"{endpoint_url}/{s3_bucket}/{s3_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amend the reading method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def my_read_method(uri):\n",
    "    parsed = urlparse(uri)\n",
    "    if parsed.scheme == 's3':\n",
    "        bucket = parsed.netloc\n",
    "        key = parsed.path[1:]\n",
    "        s3 = boto3.resource('s3')\n",
    "        obj = s3.Object(bucket, key)\n",
    "        return obj.get()['Body'].read().decode('utf-8')\n",
    "    else:\n",
    "        return StacIO.default_read_text_method(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the writing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def my_write_method(uri, txt):\n",
    "    parsed = urlparse(uri)\n",
    "#     print(parsed)\n",
    "    if (parsed.scheme == 'https') and ('s3' in parsed.netloc):\n",
    "        endpoint_url = os.getenv(\"AWS_S3_ENDPOINT_URL\")\n",
    "        s3_bucket = parsed.path.split('/')[1]\n",
    "        \n",
    "        s3_client, bucket = s3_create_client(s3_bucket)\n",
    "        \n",
    "        key = '/'.join(parsed.path.split('/')[2:])\n",
    "#         print(key)\n",
    "        s3_client.put_object(Body=txt, Bucket=s3_bucket, Key=key)\n",
    "        \n",
    "    else:\n",
    "        print('relaying to defaul')\n",
    "        StacIO.default_write_text_method(uri, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then allow us to overwrite the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pystac_setIO():\n",
    "    StacIO.read_text_method = my_read_method\n",
    "    StacIO.write_text_method = my_write_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
