{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rediswq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis Utils\n",
    "\n",
    "> Tools for managing a redis queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import redis\n",
    "import uuid\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RedisWQ(object):\n",
    "    \"\"\"Simple Finite Work Queue with Redis Backend\n",
    "    This work queue is finite: as long as no more work is added\n",
    "    after workers start, the workers can detect when the queue\n",
    "    is completely empty.\n",
    "    The items in the work queue are assumed to have unique values.\n",
    "    This object is not intended to be used by multiple threads\n",
    "    concurrently.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, **redis_kwargs):\n",
    "        \"\"\"The default connection parameters are: host='localhost', port=6379, db=0\n",
    "        The work queue is identified by \"name\".  The library may create other\n",
    "        keys with \"name\" as a prefix. \n",
    "        \"\"\"\n",
    "        self._db = redis.StrictRedis(**redis_kwargs)\n",
    "        # The session ID will uniquely identify this \"worker\".\n",
    "        self._session = str(uuid.uuid4())\n",
    "        # Work queue is implemented as two queues: main, and processing.\n",
    "        # Work is initially in main, and moved to processing when a client picks it up.\n",
    "        self._main_q_key = name\n",
    "        self._processing_q_key = name + \":processing\"\n",
    "        self._lease_key_prefix = name + \":leased_by_session:\"\n",
    "\n",
    "    def sessionID(self):\n",
    "        \"\"\"Return the ID for this session.\"\"\"\n",
    "        return self._session\n",
    "\n",
    "    def _main_qsize(self):\n",
    "        \"\"\"Return the size of the main queue.\"\"\"\n",
    "        return self._db.llen(self._main_q_key)\n",
    "\n",
    "    def _processing_qsize(self):\n",
    "        \"\"\"Return the size of the main queue.\"\"\"\n",
    "        return self._db.llen(self._processing_q_key)\n",
    "\n",
    "    def empty(self):\n",
    "        \"\"\"Return True if the queue is empty, including work being done, False otherwise.\n",
    "        False does not necessarily mean that there is work available to work on right now,\n",
    "        \"\"\"\n",
    "        return self._main_qsize() == 0 and self._processing_qsize() == 0\n",
    "\n",
    "# TODO: implement this\n",
    "#    def check_expired_leases(self):\n",
    "#        \"\"\"Return to the work queueReturn True if the queue is empty, False otherwise.\"\"\"\n",
    "#        # Processing list should not be _too_ long since it is approximately as long\n",
    "#        # as the number of active and recently active workers.\n",
    "#        processing = self._db.lrange(self._processing_q_key, 0, -1)\n",
    "#        for item in processing:\n",
    "#          # If the lease key is not present for an item (it expired or was \n",
    "#          # never created because the client crashed before creating it)\n",
    "#          # then move the item back to the main queue so others can work on it.\n",
    "#          if not self._lease_exists(item):\n",
    "#            TODO: transactionally move the key from processing queue to\n",
    "#            to main queue, while detecting if a new lease is created\n",
    "#            or if either queue is modified.\n",
    "\n",
    "    def _itemkey(self, item):\n",
    "        \"\"\"Returns a string that uniquely identifies an item (bytes).\"\"\"\n",
    "        return hashlib.sha224(item).hexdigest()\n",
    "\n",
    "    def _lease_exists(self, item):\n",
    "        \"\"\"True if a lease on 'item' exists.\"\"\"\n",
    "        return self._db.exists(self._lease_key_prefix + self._itemkey(item))\n",
    "\n",
    "    def lease(self, lease_secs=60, block=True, timeout=None):\n",
    "        \"\"\"Begin working on an item the work queue. \n",
    "        Lease the item for lease_secs.  After that time, other\n",
    "        workers may consider this client to have crashed or stalled\n",
    "        and pick up the item instead.\n",
    "        If optional args block is true and timeout is None (the default), block\n",
    "        if necessary until an item is available.\"\"\"\n",
    "        if block:\n",
    "            item = self._db.brpoplpush(self._main_q_key, self._processing_q_key, timeout=timeout)\n",
    "        else:\n",
    "            item = self._db.rpoplpush(self._main_q_key, self._processing_q_key)\n",
    "        if item:\n",
    "            # Record that we (this session id) are working on a key.  Expire that\n",
    "            # note after the lease timeout.\n",
    "            # Note: if we crash at this line of the program, then GC will see no lease\n",
    "            # for this item a later return it to the main queue.\n",
    "            itemkey = self._itemkey(item)\n",
    "            self._db.setex(self._lease_key_prefix + itemkey, lease_secs, self._session)\n",
    "        return item\n",
    "\n",
    "    def complete(self, value):\n",
    "        \"\"\"Complete working on the item with 'value'.\n",
    "        If the lease expired, the item may not have completed, and some\n",
    "        other worker may have picked it up.  There is no indication\n",
    "        of what happened.\n",
    "        \"\"\"\n",
    "        self._db.lrem(self._processing_q_key, 0, value)\n",
    "        # If we crash here, then the GC code will try to move the value, but it will\n",
    "        # not be here, which is fine.  So this does not need to be a transaction.\n",
    "        itemkey = self._itemkey(value)\n",
    "        self._db.delete(self._lease_key_prefix + itemkey, self._session)\n",
    "\n",
    "# TODO: add functions to clean up all keys associated with \"name\" when\n",
    "# processing is complete.\n",
    "\n",
    "# TODO: add a function to add an item to the queue.  Atomically\n",
    "# check if the queue is empty and if so fail to add the item\n",
    "# since other workers might think work is done and be in the process\n",
    "# of exiting.\n",
    "\n",
    "# TODO(etune): move to my own github for hosting, e.g. github.com/erictune/rediswq-py and\n",
    "# make it so it can be pip installed by anyone (see\n",
    "# http://stackoverflow.com/questions/8247605/configuring-so-that-pip-install-can-work-from-github)\n",
    "\n",
    "# TODO(etune): finish code to GC expired leases, and call periodically\n",
    "#  e.g. each time lease times out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_rediswq.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01A_pleiades.ipynb.\n",
      "Converted 01B_pleiades_prep_worker.ipynb.\n",
      "Converted 02A_spot.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
